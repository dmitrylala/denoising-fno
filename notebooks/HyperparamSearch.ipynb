{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cafe0cb-2973-4851-9081-73cbe196677b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24ba8cdf-0d0b-4bdb-b015-a03c10f7fb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "from config import Environment, TrainConfig\n",
    "from denoising.train import prepare_training\n",
    "from denoising.utils import seed_everything\n",
    "from denoising.models.utils import count_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55f59c6a-46f9-4d45-a382-6a3b3b9326f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/d.nesterov/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdmitrylala\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CWD = Path.cwd()\n",
    "env = Environment(_env_file=CWD / '../env')\n",
    "wandb.login(key=env.wandb_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc80ed5f-c129-4b48-8d67-6529329df42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_train_cfg(trial) -> TrainConfig:\n",
    "    n_layers = trial.suggest_int('n_layers', 2, 10, log=True)\n",
    "    hidden_channels = trial.suggest_categorical('hidden_channels', [4, 8, 16, 32])\n",
    "    n_modes = trial.suggest_categorical('n_modes', [16])\n",
    "    lifting_channel_ratio = trial.suggest_categorical('lifting_channel_ratio', [2, 4, 8, 16, 32])\n",
    "    projection_channel_ratio = trial.suggest_categorical('projection_channel_ratio', [2, 4, 8, 16, 32])\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-3, log=True)\n",
    "\n",
    "    print(\n",
    "        f'Running with {n_layers=}, {hidden_channels=}, {n_modes=}, {lifting_channel_ratio=}, {projection_channel_ratio=} {lr=}'\n",
    "    )\n",
    "\n",
    "    cfg = TrainConfig(\n",
    "        # Datasets params\n",
    "        train_dset='sidd_train',\n",
    "        test_dset='sidd_test',\n",
    "        train_batch_size=16,\n",
    "        test_batch_size=32,\n",
    "        # Model params\n",
    "        name_model='sidd-hno',\n",
    "        cfg_fno={\n",
    "            'n_modes': (n_modes, n_modes),\n",
    "            'in_channels': 3,\n",
    "            'hidden_channels': hidden_channels,\n",
    "            'lifting_channel_ratio': lifting_channel_ratio,\n",
    "            'projection_channel_ratio': projection_channel_ratio,\n",
    "            'out_channels': 3,\n",
    "            'factorization': 'dense',\n",
    "            'n_layers': n_layers,\n",
    "            'rank': 0.42,\n",
    "            'spectral': 'hartley',\n",
    "        },\n",
    "        # Run params\n",
    "        random_seed=42,\n",
    "        device='cuda:2',\n",
    "        run_name='Run optuna',\n",
    "        # Train params\n",
    "        n_epochs=1,\n",
    "        lr=lr,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    return cfg\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    cfg = define_train_cfg(trial)\n",
    "    trainer, train_kwargs, _ = prepare_training(env, cfg)\n",
    "\n",
    "    if count_parameters(trainer.model) > 5_000_000:\n",
    "        print('Pruned by model params')\n",
    "        raise optuna.exceptions.TrialPruned\n",
    "\n",
    "    seed_everything(cfg.random_seed)\n",
    "\n",
    "    trial_obj = 'test_h1'\n",
    "    metrics = trainer.train(trial=trial, trial_obj=trial_obj, **train_kwargs)\n",
    "\n",
    "    return float(metrics[trial_obj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ece7123f-920b-4691-9f96-d7b4cfda08b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = 'hno-sidd'\n",
    "study_name = f'{run_name}-optuna'\n",
    "sampler_path = Path(f'./{run_name}-sampler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed12a952-0bfc-4334-a1d1-2a70001d04be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 16:20:45,492] Using an existing study with name 'hno-sidd-optuna' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restore sampler from path: hno-sidd-sampler\n",
      "Using an existing study with name 'hno-sidd-optuna' instead of creating a new one.\n",
      "Using an existing study with name 'hno-sidd-optuna' instead of creating a new one.\n",
      "Running with n_layers=8, hidden_channels=4, n_modes=16, lifting_channel_ratio=8, projection_channel_ratio=32 lr=0.0003537913969983926\n",
      "Got n_samples = 8380  in dataset mri_pm_train        with sample size = torch.Size([1, 145, 145])\n",
      "Got n_samples = 2093  in dataset mri_pm_test         with sample size = torch.Size([1, 145, 145])\n",
      "Got n_samples = 6704  in dataset mri_gt_train        with sample size = torch.Size([1, 145, 145])\n",
      "Got n_samples = 1676  in dataset mri_gt_val          with sample size = torch.Size([1, 145, 145])\n",
      "Got n_samples = 2093  in dataset mri_gt_test         with sample size = torch.Size([1, 145, 145])\n",
      "Got n_samples = 137   in dataset bsd_synth_0.01_train with sample size = torch.Size([1, 321, 481])\n",
      "Got n_samples = 77    in dataset bsd_synth_0.01_test with sample size = torch.Size([1, 321, 481])\n",
      "Got n_samples = 12296 in dataset sidd_train          with sample size = torch.Size([3, 512, 512])\n",
      "Got n_samples = 3008  in dataset sidd_test           with sample size = torch.Size([3, 512, 512])\n",
      "torch.Size([16, 3, 512, 512]) torch.Size([16, 3, 512, 512])\n",
      "Loaded  model mri-fno-neuralop with n_parameters = 2010449\n",
      "Loaded  model mri-fno-tucker   with n_parameters = 2010449\n",
      "Loaded  model mri-fno-dense    with n_parameters = 4476513\n",
      "Loaded  model mri-hno          with n_parameters = 1098977\n",
      "Loaded  model mri-hno-optuned  with n_parameters = 10552961\n",
      "Loaded  model mri-fno-optuned  with n_parameters = 4197273\n",
      "Loaded  model mri-hno-gt-optuned with n_parameters = 4223585\n",
      "Loaded  model mri-fno-gt-optuned with n_parameters = 212765\n",
      "Loaded  model sidd-fno-run2    with n_parameters = 2011091\n",
      "Loaded  model sidd-fno-run3    with n_parameters = 2011091\n",
      "Loaded  model sidd-fno-run4    with n_parameters = 2028627\n",
      "Loaded  model bsd-fno          with n_parameters = 2010449\n",
      "Created model sidd-hno         with n_parameters = 132791\n",
      "Logging to wandb enabled: False\n",
      "Training on 12296 samples\n",
      "Testing on [3008] samples         on resolutions ['test'].\n",
      "Raw outputs of shape torch.Size([16, 3, 512, 512])\n",
      "[0] time=446.86, avg_loss=2.8354, train_err=45.3370\n",
      "Eval: test_h1=2.7180, test_l2=1.8245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-10 16:29:17,733] Trial 1 finished with value: 2.717987060546875 and parameters: {'n_layers': 8, 'hidden_channels': 4, 'n_modes': 16, 'lifting_channel_ratio': 8, 'projection_channel_ratio': 32, 'lr': 0.0003537913969983926}. Best is trial 1 with value: 2.717987060546875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved training state to ckpt\n",
      "Trial 1 finished with value: 2.717987060546875 and parameters: {'n_layers': 8, 'hidden_channels': 4, 'n_modes': 16, 'lifting_channel_ratio': 8, 'projection_channel_ratio': 32, 'lr': 0.0003537913969983926}. Best is trial 1 with value: 2.717987060546875.\n",
      "Trial 1 finished with value: 2.717987060546875 and parameters: {'n_layers': 8, 'hidden_channels': 4, 'n_modes': 16, 'lifting_channel_ratio': 8, 'projection_channel_ratio': 32, 'lr': 0.0003537913969983926}. Best is trial 1 with value: 2.717987060546875.\n",
      "Running with n_layers=3, hidden_channels=16, n_modes=16, lifting_channel_ratio=2, projection_channel_ratio=8 lr=0.0003695278044736918\n",
      "Got n_samples = 8380  in dataset mri_pm_train        with sample size = torch.Size([1, 145, 145])\n",
      "Got n_samples = 2093  in dataset mri_pm_test         with sample size = torch.Size([1, 145, 145])\n",
      "Got n_samples = 6704  in dataset mri_gt_train        with sample size = torch.Size([1, 145, 145])\n",
      "Got n_samples = 1676  in dataset mri_gt_val          with sample size = torch.Size([1, 145, 145])\n",
      "Got n_samples = 2093  in dataset mri_gt_test         with sample size = torch.Size([1, 145, 145])\n",
      "Got n_samples = 137   in dataset bsd_synth_0.01_train with sample size = torch.Size([1, 321, 481])\n",
      "Got n_samples = 77    in dataset bsd_synth_0.01_test with sample size = torch.Size([1, 321, 481])\n",
      "Got n_samples = 12296 in dataset sidd_train          with sample size = torch.Size([3, 512, 512])\n",
      "Got n_samples = 3008  in dataset sidd_test           with sample size = torch.Size([3, 512, 512])\n",
      "torch.Size([16, 3, 512, 512]) torch.Size([16, 3, 512, 512])\n",
      "Loaded  model mri-fno-neuralop with n_parameters = 2010449\n",
      "Loaded  model mri-fno-tucker   with n_parameters = 2010449\n",
      "Loaded  model mri-fno-dense    with n_parameters = 4476513\n",
      "Loaded  model mri-hno          with n_parameters = 1098977\n",
      "Loaded  model mri-hno-optuned  with n_parameters = 10552961\n",
      "Loaded  model mri-fno-optuned  with n_parameters = 4197273\n",
      "Loaded  model mri-hno-gt-optuned with n_parameters = 4223585\n",
      "Loaded  model mri-fno-gt-optuned with n_parameters = 212765\n",
      "Loaded  model sidd-fno-run2    with n_parameters = 2011091\n",
      "Loaded  model sidd-fno-run3    with n_parameters = 2011091\n",
      "Loaded  model sidd-fno-run4    with n_parameters = 2028627\n",
      "Loaded  model bsd-fno          with n_parameters = 2010449\n",
      "Created model sidd-hno         with n_parameters = 791419\n",
      "Logging to wandb enabled: False\n",
      "Training on 12296 samples\n",
      "Testing on [3008] samples         on resolutions ['test'].\n",
      "Raw outputs of shape torch.Size([16, 3, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "# init trials storage and sampler pickle\n",
    "optuna.logging.get_logger('optuna').addHandler(logging.StreamHandler(sys.stdout))\n",
    "storage_name = 'sqlite:///{}.db'.format(study_name)\n",
    "restored_sampler = None\n",
    "if sampler_path.exists():\n",
    "    print(f'Restore sampler from path: {sampler_path}')\n",
    "    restored_sampler = pickle.load(Path.open(sampler_path, 'rb'))\n",
    "\n",
    "# create new study or restore\n",
    "study = optuna.create_study(\n",
    "    study_name=study_name,\n",
    "    storage=storage_name,\n",
    "    direction='minimize',\n",
    "    sampler=restored_sampler,\n",
    "    load_if_exists=True,\n",
    ")\n",
    "\n",
    "if not sampler_path.exists():\n",
    "    print(f'Caching sampler in: {sampler_path}')\n",
    "    pickle.dump(study.sampler, Path.open(sampler_path, 'wb'))\n",
    "\n",
    "# run optimization\n",
    "study.optimize(objective, n_trials=100, timeout=12000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7b8d34-a081-4af7-b1b3-d4df7d0e760f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e68ac1f-902d-4e17-a7db-a1e90fc88270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  132\n",
      "  Number of pruned trials:  54\n",
      "  Number of complete trials:  77\n",
      "Best trial:\n",
      "  Value:  0.3016343414783478\n",
      "  Params: \n",
      "    n_layers: 4\n",
      "    hidden_channels: 32\n",
      "    n_modes: 16\n",
      "    lifting_channel_ratio: 16\n",
      "    projection_channel_ratio: 2\n",
      "    lr: 0.005083610315160994\n"
     ]
    }
   ],
   "source": [
    "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "print('Study statistics: ')\n",
    "print('  Number of finished trials: ', len(study.trials))\n",
    "print('  Number of pruned trials: ', len(pruned_trials))\n",
    "print('  Number of complete trials: ', len(complete_trials))\n",
    "\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "\n",
    "print('  Value: ', trial.value)\n",
    "\n",
    "print('  Params: ')\n",
    "for key, value in trial.params.items():\n",
    "    print('    {}: {}'.format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f6a8097-e866-4fd1-85f7-41f03838fb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HNO on mri gt v2\n",
    "# Study statistics: \n",
    "#   Number of finished trials:  132\n",
    "#   Number of pruned trials:  54\n",
    "#   Number of complete trials:  77\n",
    "# Best trial:\n",
    "#   Value:  0.3016343414783478\n",
    "#   Params: \n",
    "#     n_layers: 4\n",
    "#     hidden_channels: 32\n",
    "#     n_modes: 16\n",
    "#     lifting_channel_ratio: 16\n",
    "#     projection_channel_ratio: 2\n",
    "#     lr: 0.005083610315160994\n",
    "\n",
    "# FNO on mri gt\n",
    "# Study statistics: \n",
    "#   Number of finished trials:  91\n",
    "#   Number of pruned trials:  49\n",
    "#   Number of complete trials:  41\n",
    "# Best trial:\n",
    "#   Value:  0.29339370131492615\n",
    "#   Params: \n",
    "#     n_layers: 3\n",
    "#     hidden_channels: 32\n",
    "#     n_modes: 32\n",
    "#     lifting_channel_ratio: 32\n",
    "#     projection_channel_ratio: 4\n",
    "#     lr: 0.005342701181994739\n",
    "\n",
    "# HNO on mri gt\n",
    "# Study statistics: \n",
    "#   Number of finished trials:  32\n",
    "#   Number of pruned trials:  10\n",
    "#   Number of complete trials:  21\n",
    "# Best trial:\n",
    "#   Value:  0.3213663101196289\n",
    "#   Params: \n",
    "#     n_layers: 6\n",
    "#     hidden_channels: 8\n",
    "#     n_modes: 16\n",
    "#     lifting_channel_ratio: 8\n",
    "#     projection_channel_ratio: 4\n",
    "#     lr: 0.004377779250650843\n",
    "\n",
    "# FNO\n",
    "# Study statistics: \n",
    "#   Number of finished trials:  29\n",
    "#   Number of pruned trials:  9\n",
    "#   Number of complete trials:  20\n",
    "# Best trial:\n",
    "#   Value:  0.08233946561813354\n",
    "#   Params: \n",
    "#     n_layers: 15\n",
    "#     hidden_channels: 16\n",
    "#     n_modes: 32\n",
    "#     lifting_channel_ratio: 32\n",
    "#     projection_channel_ratio: 2\n",
    "#     lr: 0.006055187761870968\n",
    "\n",
    "# HNO\n",
    "# Study statistics: \n",
    "#   Number of finished trials:  55\n",
    "#   Number of pruned trials:  31\n",
    "#   Number of complete trials:  24\n",
    "# Best trial:\n",
    "#   Value:  0.08180370926856995\n",
    "#   Params: \n",
    "#     n_layers: 10\n",
    "#     hidden_channels: 16\n",
    "#     n_modes: 16\n",
    "#     lifting_channel_ratio: 32\n",
    "#     projection_channel_ratio: 8\n",
    "#     lr: 0.00433647012426727"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bddc271-505f-4f55-8908-12ff56cace8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HNO-v2, test_h1\n",
    "# Study statistics:\n",
    "#   Number of finished trials:  25\n",
    "#   Number of pruned trials:  16\n",
    "#   Number of complete trials:  9\n",
    "# Best trial:\n",
    "#   Value:  0.10859087109565735\n",
    "#   Params:\n",
    "#     n_layers: 2\n",
    "#     hidden_channels: 41\n",
    "#     n_modes: 8\n",
    "#     lifting_channel_ratio: 6\n",
    "#     projection_channel_ratio: 32\n",
    "#     lr: 0.0026019787737744096\n",
    "\n",
    "\n",
    "# HNO-v2, test_l2\n",
    "\n",
    "# Study statistics:\n",
    "#   Number of finished trials:  31\n",
    "#   Number of pruned trials:  13\n",
    "#   Number of complete trials:  17\n",
    "# Best trial:\n",
    "#   Value:  0.043848007917404175\n",
    "#   Params:\n",
    "#     n_layers: 3\n",
    "#     hidden_channels: 49\n",
    "#     n_modes: 16\n",
    "#     lifting_channel_ratio: 6\n",
    "#     projection_channel_ratio: 12\n",
    "#     lr: 0.0074820412780186325"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5f2aa8-64da-4ee1-b33a-9fddb50166ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf7c313-3b9b-48fb-b2d5-7dbaacfb251b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f7e335-666c-44a3-891e-98e4967a985c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2726ff26-df7e-4f63-b3c2-74a746c238f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cec6797-9808-44a4-8e94-d3921bb574f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae32836-af75-4446-9aee-24764a35adad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc565710-10bd-4a97-ae71-5dcbd2309995",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
